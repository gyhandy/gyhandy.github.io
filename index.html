<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
    <head>
    <meta name="google-site-verification" content="eoPCGBBxDIK0Ff9Dk_dXsuHMTNzzSEZMbsfO4zriBK8" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="keywords" content="Yunhao Ge, SJTU, Shanghai Jiao Tong University, UII, United Imaging Intelligence, SDU, ShanDong University ">
    <meta name="description" content="Yunhao Ge's home page">
<!--    <link href="main.css" media="all" rel="stylesheet">-->
    <link rel="stylesheet" href="jemdoc.css" type="text/css">
    <title>Yunhao (Andy) Ge</title>
    </head>

<body>


<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">
					<h1>Yunhao (Andy) Ge</h1><h1>
					<h1>葛云皓</h1><h1>
				</h1></div>

				<h3>2nd Year CS Ph.D. Student</h3>
                <h3>ilab @ USC</h3>
				<p>
					Rm B06, Hedco Neurosciences Building <br>
					University of Southern California <br>
					3641 Watt Way, Los Angeles, CA 90089-2520, USA <br>
					<br>
					Email: yunhaoge at usc dot edu
				</p>
				<p> <a href="https://scholar.google.com/citations?hl=en&user=QhjGr4oAAAAJ=en"><img src="./pics/google_scholar.png" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/gyhandy"><img src="./pics/github_s.jpg" height="40px" style="margin-bottom:-3px"></a>
                    <a href="https://www.linkedin.com/in/yunhao-ge-720727135"><img src="./pics/LinkedIn_s.png" height="40px" style="margin-bottom:-3px"></a>
                    <a href="files/CV_YunhaoGe.pdf"><img src="./pics/cv.png" height="40px" style="margin-bottom:-3px"></a>

					<!--
					<a href="https://www.researchgate.net/profile/Xianzhi_Li2"><img src="./pic/rg.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://zh-cn.facebook.com/people/Lequan-Yu/100003696557697"><img src="./pic/Facebook_s.png" height="30px" style="margin-bottom:-3px"></a>
					-->
				</p>
			</td>
			<td>
				<img src="pics/Yunhao Ge.jpg" border="0" width="260"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>



<h2>About Me</h2>
<p>I am now a 2nd-year PhD student in <a  href="http://ilab.usc.edu/">iLab</a> at <a  href="https://www.cs.usc.edu/">University of Southern University</a> (USC),
   working with Prof. <a  target="_blank" href=https://scholar.google.com/citations?user=xhUvqK8AAAAJ&hl=en target="_blank" rel="external">Laurent Itti</a>.
	I also work closely with Dr. <a  target="_blank" href=http://wuziyan.com/ target="_blank" rel="external"> Ziyan Wu </a> (<a  target="_blank" href="https://www.uii-ai.com/en/" target="_blank" rel="external">UII America</a>).
 Before that, I got my M.Sc. degree at Robotics Institute at <a  target="_blank" href="http://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a>
    (SJTU), advised by Prof. Yanzheng Zhao and Prof. Weixin Yan. And I got my B.Eng. degree of Mechatronics at <a  target="_blank" href="http://www.en.sdu.edu.cn/"> Shandong University</a> (SDU),
    advised by Prof. Shujiang Chen.  </p>
	I'm interested in Machine Learning, Computer vision, and their applications towards Artificial General Intelligence (AGI). My current research focuses include:
<ul>
	  <li>interpretable human-AI interaction (interpretability, steerability, disentangled representation learning)</li>
	  <li>generative models (data augmentation, how generative models boost discriminative models)</li>
	  <li>graph neural networks (structure and relationship learning)</li>
	  <li>visual reasoning, attention and saliency (cognitive learning, eye tracking)</li>
	</ul>
<!--<p>My research interests lie in Machine Learning, Computer vision, and AGI. Currently, I am focusing on simulating Cognitive Baby Learning (Imagination, Reasoning, Attention)-->
<!--by using various learning algorithms (Representation Learning, Generative models, GNN, Reinforcement Learning,  Meta-Learning, etc.).</p>-->


<!--<p>My research interests lie in Computer vision, Robotics and General AI. Currently, I am-->
<!--focusing on simulating baby learning (Reasoning, Attention, Imagination) by using various learning algorithms (Representation Learning, Adversarial Learning,-->
<!--Meta Learning, GNN, Reinforcement Learning, etc.).</p>-->
<br>

<h2>News & Updates</h2>
<ul>
	<li>
		[2021/05/17] I will be joining Computer Vision Group at <a  target="_blank" href=https://www.microsoft.com/en-us/research/ target="_blank" rel="external"> Microsoft Research </a>  Redmond as a research intern in summer 2021, advised by
        Dr. <a  target="_blank" href=http://vibhavvineet.info/ target="_blank" rel="external"> Vibhav Vineet </a>
        and Dr. <a  target="_blank" href=https://neelj.com/ target="_blank" rel="external"> Neel Joshi </a></li>
	</li>
	<li>
		[2021/05/08] Serving as a reviewer for NeurIPS 2021 and ICLR 2021!
	</li>
	<li>
		[2021/04/07] Releasing <a  target="_blank" href=http://ilab.usc.edu/datasets/i2sg target="_blank" rel="external">Img2SceneGraph</a>,
		a pipeline that transfers images to scene graphs with node attributes!
		Welcome to <a  target="_blank" href=http://ilab.usc.edu/datasets/i2sg target="_blank" rel="external"> Download </a> and try!
	</li>
	<li>
		[2021/04/02] One paper (Graph Autoencoder for Graph Compression and Representation Learning)
		was accepted by Neural Compression Workshop @ICLR 2021 as <strong style="color:blue">Spotlight</strong>!
	</li>
	<li>
		[2021/02/28] One paper (A Peek Into the Reasoning of Neural Networks: Interpreting with Structural Visual Concepts)
		was accepted by CVPR 2021!
	</li>
	<li>
		[2021/01/16] One paper (Beneficial Perturbation Network for designing general adaptive artificial intelligence systems)
		was accepted by TNNLS!
	</li>
	<li>
		[2021/01/12] One paper (Zero-shot Synthesis with Group-Supervised Learning) was accepted by ICLR 2021!
	</li>
	<li>
		[2020/09/14] <a  target="_blank" href=http://ilab.usc.edu/datasets/fonts target="_blank" rel="external"> Fonts dataset </a> was proposed for fast testing and idea iteration on disentangled representation learning and zero-shot synthesis.
			Welcome to <a  target="_blank" href=http://ilab.usc.edu/datasets/fonts target="_blank" rel="external"> Download </a> and try!
	</li>
	<li>
		[2020/07/02] One paper (Pose Augmentation: Class-agnostic Object Pose Transformation) was accepted by ECCV 2020!
	</li>
	<li>
		[2020/05/12] I will be joining UII America as a research intern in summer 2020, advised by
        Dr. <a  target="_blank" href=http://wuziyan.com/ target="_blank" rel="external"> Ziyan Wu </a>
        and Dr. <a  target="_blank" href=https://karanams.github.io/ target="_blank" rel="external"> Srikrishna Karanam </a></li>
	</li>
	<li>
		[2019/08/12] I will be joining USC CS Ph.D. Program in fall 2019, advised by
        Prof. <a  target="_blank" href=http://ilab.usc.edu/itti/ target="_blank" rel="external">Laurent Itti</a>.
	</li>
	<li>
		[2019/07/01] One paper (Synthesis and inpainting-based MR-CT registration) was accepted by MICCAI 2019.
	</li>
	<li>
		[2019/03/01] One paper (Unpaired Whole-Body Mr to CT Synthesis) was accepted by ISBI 2019.
	</li>
</ul>
<br>
<!--<h2>Education</h2>-->
<!--<hr>-->
<!--  <img id="school_logo" src="./pics/USC_logo.png">-->
<!--  <h4> University of Southern University, Los Angeles, USA (Aug. 2019 - present)</h4>-->
<!--  <ul>-->
<!--	<li>-->
<!--	  <b>PhD of Computer Science</b>, ilab @ Computer Science Department</li>-->
<!--	<li>Major Orientation: Deep Learning and Reinforcement learning for object recognition <br />Baby learning inspired causal inference </li>-->
<!--	<li>Annenberg Graduate Fellowship at University of Southern California </li>-->
<!--  </ul>-->
<!--  -->
<!--  <img id="school_logo" src="./pics/sjtu_logo.png">-->
<!--  <h4> Shanghai Jiao Tong University, Shanghai, China (Sep. 2016 - Jun. 2019)</h4>-->
<!--  <ul>-->
<!--	<li>-->
<!--	  <b>Master of Science(MSc)</b>, ROBOTICS AND INTELLIGENCE GROUP</li>-->
<!--	<li>Major Orientation: Deep Learning for Medical Image Computing(Computer Vison)<br />deep learning for Robotics and Machine Vision </li>-->
<!--	<li>Overall performance ranked: 6/210 </li>-->
<!--	<li>Excellent master's thesis "Automatic focusing and global precise imaging of <br>pathological microscope based on convolutional neural network "</li>-->
<!--  </ul>-->
<!--  -->
<!--  <img id="school_logo" src="./pics/sdu_logo.jpg">-->
<!--  <h4> Shandong University, Jinan, Shandong, China (Sep. 2012 - Jun. 2016)</h4>-->
<!--  <ul>-->
<!--	<li>-->
<!--	  <b>Bachelor of Engineering(B.Eng)</b>, MECHATRONICS </li>-->
<!--	<li>Major Orientation: Robotics Intelligent Control and Bionic Robotics</li>-->
<!--	<li>Overall performance ranked:-->
<!--	  <strong style="color:black">1/66</strong>   GPA: Overall: 86.08/100 | Major: 93.38/100 </li>-->
<!--  </ul>-->



<h2>Selected Publications [<a href="https://scholar.google.com/citations?hl=en&user=QhjGr4oAAAAJ=en&user=QhjGr4oAAAAJ">Google Scholar</a>]</h2>

<table id="tbPublications" width="100%">



	<tr>
		<td width="306">
		<img src="pics/VisualReasoning.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td>
			<b>A Peek Into the Reasoning of Neural Networks: Interpreting with Structural Visual Concepts</b><br>
<!--			<p style="color:#2E86C1 ";> <b>A Peek Into the Reasoning of Neural Networks: Interpreting with Structural Visual Concepts</b> </p><br>-->
		<br>
			<b>Yunhao Ge</b>, Yao Xiao, Zhi Xu, Meng Zheng, Srikrishna Karanam, Terrence Chen, Laurent Itti and Ziyan Wu  <br>
		<em>IEEE/ CVF International Conference on Computer Vision and Pattern Recognition </em>(<i><b>CVPR</b></i>), 2021.
		<p></p>
			<p>[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_A_Peek_Into_the_Reasoning_of_Neural_Networks_Interpreting_With_CVPR_2021_paper.pdf" target="_blank">paper</a>]
			[<a href="https://github.com/Pangyk/Graph_AE" target="_blank">code</a>]
			[<a href="http://ilab.usc.edu/andy/vrx" target="_blank">website</a>]</p>
		</td>
	</tr>




	<tr>
		<td width="306">
		<img src="pics/GraphAE.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td>
			<b>Graph Autoencoder for Graph Compression and Representation Learning</b><br>
<!--			<p style="color:#2E86C1 ";> <b>A Peek Into the Reasoning of Neural Networks: Interpreting with Structural Visual Concepts</b> </p><br>-->
		<br>
			<b>Yunhao Ge<sup>*</sup></b>, Yunkui Pang<sup>*</sup>, Linwei Li and Laurent Itti (*=equal contribution)<br>
		<em>Neural Compression: From Information Theory to Applications--Workshop@ </em>(<i><b>ICLR</b></i>), 2021.
		<p></p>
		<p>[<a href="https://openreview.net/pdf?id=Bo2LZfaVHNi" target="_blank">paper</a>]
			[<a href="https://github.com/Pangyk/Graph_AE" target="_blank">code</a>]
			[<a href="http://ilab.usc.edu/datasets/i2sg" target="_blank">Img2SceneGraph</a>]</p>
			<p><strong style="color:blue">Spotlight Presentation</strong></p>
		</td>
	</tr>



	<tr>
		<td width="306">
		<img src="pics/GSL3.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Zero-shot Synthesis with Group-Supervised Learning</b> <br>
		<br>
		<b>Yunhao Ge</b>, Sami Abu-El-Haija, Gan Xin and Laurent Itti  <br>
		<em>International Conference on Learning Representations </em>(<i><b>ICLR</b></i>), 2021.
		<p></p>
		<p>[<a href="https://arxiv.org/pdf/2009.06586.pdf" target="_blank">paper</a>]
			[<a href="https://github.com/gyhandy/Group-Supervised-Learning" target="_blank">code</a>]
			[<a href="http://sami.haija.org/iclr21gsl" target="_blank">website</a>]
			[<a href="http://ilab.usc.edu/datasets/fonts" target="_blank">Fonts Dataset</a>]
			[<a href="https://zhuanlan.zhihu.com/p/364895887" target="_blank">知乎</a>]
			[<a href="https://mp.weixin.qq.com/s/o2HBYf3NF3UsMxUqkASdyg" target="_blank">AI科技评论</a>]
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="pics/eccv.gif" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Pose Augmentation: Class-agnostic Object Pose Transformation for Object Recognition</b> <br>
			<br>
		<b>Yunhao Ge</b>, Jiaping Zhao, Laurent Itti  <br>
		<em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2020.
		<p></p>
		<p>[<a href="https://arxiv.org/pdf/2003.08526.pdf" target="_blank">paper</a>]
			[<a href="https://github.com/gyhandy/Pose-Augmentation" target="_blank">code</a>]
			[<a href="https://youtu.be/WHAFj9KXRFY" target="_blank">video-1min</a>]
			[<a href="https://youtu.be/9N8eyOmCWh4" target="_blank">video-10min</a>]</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

	<tr>
		<td width="306">
		<img src="pics/Beneficial.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Beneficial Perturbation Network for designing general adaptive artificial intelligence systems</b> <br>
			<br>
		Shixian Wen, Amanda Rios<sup>*</sup>, <b>Yunhao Ge<sup>*</sup></b> and Laurent Itti (*=equal contribution) <br>
		<em> IEEE Transactions on Neural Networks and Learning Systems </em>(<i><b>TNNLS</b></i>), 2021.
		<p></p>
		<p>[<a href="https://arxiv.org/pdf/2009.13954.pdf" target="_blank">paper</a>]
		</td>




    <tr>
		<td width="306">
		<img src="pics/project11.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Unpaired MR to CT Synthesis with Explicit Structural Constrained Adversarial Learning</b> <br>
			 <br>
		<b>Yunhao Ge<sup>*</sup></b>, Dongming Wei<sup>*</sup>, Zhong Xue, Yiqiang Zhan, Xiang Zhou, Qian Wang and Shu Liao (*=equal contribution)<br>
		<em>IEEE International Symposium on Biomedical Imaging</em> (<i><b>ISBI</b></i>), 2019.
		<p></p>
		<p>[<a href="files/UNPAIRED.pdf" target="_blank">paper</a>]
            [<a href="https://github.com/gyhandy/Unpaired-Cross-modality-Image-Synthesis" target="_blank">code</a>]</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>


    <tr>
		<td width="306">
		<img src="pics/SLIR-MedIA.jpg" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Synthesis and inpainting-based MR-CT registration for image-guided thermal ablation of liver tumors</b> <br>
			<br>
		Dongming Wei, Sahar Ahmad, Jiayu Huo, Wen Peng, <b>Yunhao Ge</b>, Zhong Xue, Pew-Thian Yap, Wentao Li, Dinggang Shen, Qian Wang <br>
		<em>International Conference on Medical Image Computing and Computer-Assisted Intervention</em> (<i><b>MICCAI</b></i>), 2019.
		<p></p>
		<p>[<a href="https://arxiv.org/pdf/1907.13020.pdf" target="_blank">paper</a>]</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="pics/SPIE1.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Unpaired Whole-body MR to CT Synthesis with Correlation Coefficient Constrained Adversarial Learning</b> <br>
			<br>
		<b>Yunhao Ge</b>, Zhong Xue, Yiqiang Zhan, Xiang Zhou and Shu Liao <br>
		<em>SPIE-Medical Imaging</em> (<i><b>SPIE</b></i>), 2019.
		<p></p>
		<p>[<a href="files/SPIE.pdf" target="_blank">paper</a>]
            [<a href="https://github.com/gyhandy/Unpaired-Cross-modality-Image-Synthesis" target="_blank">code</a>]</p>

		<p><strong style="color:blue">Oral Presentation</strong></p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>


    <tr>
		<td width="306">
		<img src="pics/project3.png" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>A Real-time Gesture Prediction System Using Neural Networks and Multimodal Fusion
					based on Data Glove</b> <br>
			<br>
		<b>Yunhao Ge</b>, Bin Li and Weixin Yan <br>
		<em>IEEE International Conference on Advanced Computational Intelligence</em> (<i><b>ICACI</b></i>), 2018.
		<p></p>
		<p>[<a href="files/Real.pdf" target="_blank">paper</a>]</p>
			<p><strong style="color:blue">Oral Presentation</strong></p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="pics/HHnet.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>HH-Net: Image driven microscope fast auto-focus with deep neural network</b><br>
			<br>
		<b>Yunhao Ge</b>, Bin Li, Yanzheng Zhao and Weixin Yan <br>
		<em>International Conference on Biomedical Engineering and Technology</em> (<i><b>ICBET</b></i>), 2019.
		<p></p>
		<p>[<a href="files/HH-net.pdf" target="_blank">paper</a>]
        </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="pics/project4.png" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Melanoma Segmentation and Classification in Clinical Images Using Deep Learning</b><br>
			<br>
		<b>Yunhao Ge</b>, Bin Li and Weixin Yan <br>
		<em>ACM International Conference on Machine Learning and Computing</em> (<i><b>ICMLC</b></i>), 2018.
		<p></p>
		<p>[<a href="files/Melanoma.pdf" target="_blank">paper</a>][<a  target="_blank" href="https://dl.acm.org/citation.cfm?id=3195164">Paper Link</a>]
        </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

    <tr>
		<td width="306">
		<img src="pics/project5.png" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
		</td>
		<td> <b>Benign and Malignant Mammographic Image Classification based on Convolutional
					Neural Networks</b><br>
			<br>
		Bin Li, <b>Yunhao Ge</b>, Yanzheng Zhao, Enguang Guan and Weixin Yan <br>
		<em>ACM International Conference on Machine Learning and Computing</em> (<i><b>ICMLC</b></i>), 2018.
		<p></p>
		<p>[<a href="files/Benign.pdf" target="_blank">paper</a>][<a  target="_blank" href="https://dl.acm.org/citation.cfm?id=3195163&dl=ACM&coll=DL">Paper Link</a>]
        </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    <tr>&nbsp</tr>
    <tr>&nbsp</tr>

<!--    <tr>-->
<!--		<td width="306">-->
<!--		<img src="pics/project.png" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">-->
<!--		</td>-->
<!--		<td> <b>Effect of Mechanical Error on Dual-Wedge Laser Scanning System and Error Correction</b><br>-->
<!--			<br>-->
<!--		<b>Yunhao Ge</b>, Jihao Liu, Fenfen Xue, Enguang Guan, Weixin Yan and Yanzheng Zhao <br>-->
<!--		<i><b>Applied Optics</b></i>, 2018.-->
<!--		<p></p>-->
<!--		<p>[<a href="files/Effect.pdf" target="_blank">paper</a>][<a  target="_blank" href="https://www.osapublishing.org/ao/abstract.cfm?uri=ao-57-21-6047">Paper Link</a>]-->
<!--        </p>-->
<!--		</td>-->
<!--	</tr>-->
<!--	<tr>&nbsp</tr>-->
<!--    <tr>&nbsp</tr>-->
<!--    <tr>&nbsp</tr>-->

<!--    <tr>-->
<!--		<td width="306">-->
<!--		<img src="pics/project8.png" width="285px" style="box-shadow: 4px 4px 8px #888">-->
<!--		</td>-->
<!--		<td> <b>Dynamic Drive Performances of the Bionic Suction Cup Actuator Based on Shape Memory Alloy</b><br>-->
<!--		<b>Yunhao Ge</b>, Jihao Liu, Bin Li, Weixin Yan and Yanzheng Zhao  <br>-->
<!--		<em>Intelligent Robotics and Applications</em> (<i><b>ICIRA</b></i>), 2017.-->
<!--		<p></p>-->
<!--		<p>[<a href="files/Dynamic.pdf" target="_blank">paper</a>][<a  target="_blank" href="https://link.springer.com/chapter/10.1007%2F978-3-319-65289-4_2">Paper Link</a>]-->
<!--        </p>-->
<!--		</td>-->
<!--	</tr>-->
<!--	<tr>&nbsp</tr>-->
<!--    <tr>&nbsp</tr>-->
<!--    <tr>&nbsp</tr>-->


<!--	<tr>-->
<!--		<td width="306">-->
<!--		<img src="pics/project7.png" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">-->
<!--		</td>-->
<!--		<td><strong>Interactive Experience across Modern Age and Tradition: Application of Arduino in Shadow Play</strong><br>-->
<!--            <em>Kun Yin, <b>Yunhao Ge</b>, Heshan Liu and Yongquan Yin  <br></em>-->
<!--            <em>Advances in Mechatronics and Machinery </em>.-->
<!--			<br>[<a target="_blank" href="files/Interactive.pdf">PDF</a>] [<a  target="_blank" href="https://www.scientific.net/AMM.868.242">Paper Link</a>]-->
<!--&lt;!&ndash;		<br>[<a  target="_blank" href="https://www.scientific.net/AMM.868.242">Paper Link</a>]&ndash;&gt;-->
<!--        <br><br>-->
<!--		</td>-->
<!--	</tr>-->



</table>
<br>
<h2>Intern & Work Experience</h2>


      <h4> Microsoft Research, Redmond, USA  (May. 2021 - Aug. 2021) </h4>
	  <ul>
        <li>Position: Research Intern in <a  target="_blank" href="https://www.microsoft.com/en-us/research/research-area/computer-vision/?facet%5Btax%5D%5Bmsr-research-area%5D%5B0%5D=13562&sort_by=most-recent" target="_blank" rel="external">Computer Vision Group</a></li>
		  <li>Supervisor: Dr. <a  target="_blank" href=http://vibhavvineet.info/ target="_blank" rel="external"> Vibhav Vineet </a>
            and Dr. <a  target="_blank" href=https://neelj.com/ target="_blank" rel="external"> Neel Joshi </a></li>
        <li>Project: Generative models, data augmentation and few shot learning </li>
    </ul>

<!--    <img id="school_logo" src="./pics/uII.png">-->
      <h4> UII America, Inc, Boston, USA  (May. 2020 - Aug. 2020) </h4>
	  <ul>
        <li>Position: Research Intern in <a  target="_blank" href="https://www.uii-ai.com/en/" target="_blank" rel="external">UII America</a></li>
        <li>Supervisor: Dr. <a  target="_blank" href=http://wuziyan.com/ target="_blank" rel="external"> Ziyan Wu </a>
            and Dr. <a  target="_blank" href=https://karanams.github.io/ target="_blank" rel="external"> Srikrishna Karanam </a></li>
        <li>Project: General Visual Reasoning Framework </li>
    </ul>

<!--    <img id="school_logo" src="./pics/Flexiv.png">-->
          <!--<h4> The University of North Carolina at Chapel Hill, NC, USA  & <br> Shanghai United ImagingIntelligence Co., Ltd, China  (Jun. 2018 - Nov. 2018)</br> </h4>-->
          <h4> Flexiv Ltd, Shanghai, China  (May. 2019 - Aug. 2019) </h4>
          <ul>
            <li>Position: Computer Vision Engineer in <a  target="_blank" href="http://flexiv.com/" target="_blank" rel="external">Flexiv Robotics</a></li>
            <li>Supervisor: Prof.<a  target="_blank" href=http://webcache.googleusercontent.com/search?q=cache:http://mvig.sjtu.edu.cn/ target="_blank" rel="external"> Cewu Lu</a> and Dr. Shuyun chong</li>
            <li>Project: Robotics adaptive massage based on human pose detection and tracking </li>
            <br/>
            <br/>
            <td width="306">
            <img src="pics/masage.gif" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
            </td>
      </ul>

<!--    <img id="school_logo" src="./pics/uII.png">-->
      <h4> United Imaging Intelligence Co., Ltd, Shanghai, China  (Jun. 2018 - Apr. 2019) </h4>
	  <ul>
        <li>Position: Research Intern in <a  target="_blank" href="https://www.uii-ai.com/en/" target="_blank" rel="external">United Imaging Intelligence</a></li>
        <li>Supervisor: Prof.<a  target="_blank" href=https://scholar.google.com/citations?user=v6VYQC8AAAAJ&hl=zh-CN target="_blank" rel="external"> Dinggang Shen</a>
        and Dr. <a  target="_blank" href=https://scholar.google.com/citations?user=INL-unYAAAAJ&hl=en target="_blank" rel="external"> Shu Liao </a></li>
        <li>Project: Unpaired Image Synthesis with Adversarial Learning </li>
    </ul>


<br>

<h2>Scholarships</h2>
      <ul>
		<li>
          Aug 2019 <b>Annenberg Graduate Fellowship at University of Southern California</b></li>
        <li>
          Sep 2017 <b>National Scholarship(Graduate)</b>, (highest honor for graduates) <strong style="color:blue">top 1% nationwide</strong></li>
        <li>
          Sep 2015 <b>National Scholarship(Undergraduate)</b>, (highest honor for undergraduates, top 2% nationwide) </li>
		<li>
          May 2018 <b>KaiYuan Motivational Scholarship</b> <strong style="color:blue">top 0.5% in Shanghai Jiao Tong University</strong></li>
        <li>
          Sep 2015 <b>Presidential Scholarship</b>, (highest honor in Shandong University) <strong style="color:blue">top 0.2% in Shan Dong University</strong></li>
        <li>
          Sep 2015 <b>BaoGang Excellent student Scholarship</b>, (4 Places per year at Shandong University) </li>
		<li>
          Sep 2015 &amp; Sep 2014 &amp; Sep 2015</b> <b>First Prize Scholarship</b> (Top 6% in China,three-year continuous)</li>
      </ul>

<br>
<h2>Honors and Awards</h2>
      <ul>
        <li>
          Aug 2017 <b>The First Prize</b> 2017 ROBOMASTER <strong style="color:blue">The World’s Leading Robotics Competition</strong> (Responsible for the design
of electronic control in robotics)[<a  target="_blank" href="https://github.com/gyhandy/Andy">Code-T_Infantry</a>]</li>
		<li>
          Aug 2017 <b>Rank 1st</b> (preliminary competition) , Tianchi: Precision medical competition-Artificial Intelligence Aided
genetic risk prediction of diabetes [<a  target="_blank" href="https://github.com/gyhandy/Diabetes-Mellitus">Code-Pred_diabetes</a>]</li>
        <li>
          Oct 2015 <b>The First Prize</b> 9th international college students ican innovation and entrepreneurship contest</li>
        <li>
          Oct 2015 <b>The Special prize(Top 1%)</b> 6th National University Students Process Equipment Practice and Innovation Competition</li>
		<li>
          Aug 2015 <b>The Silver prize</b> 8th national college students in energy saving social practice and science and technology competition </li>        
      </ul>

<br>
  <h2>Software & Patents</h2>
<table id="tbPublications" width="100%">


	<tr>
        <td width="306">
        <img src="pics/uspatent.png" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
        </td>
        <td><strong>Systems and methods for image processing</strong><br>
            <em> S Liao, <b>GE Yunhao</b>, WEI Dongming<br></em>
            <em>US Patent App. 16/729,303</em>.
<!--        <br>[<a href="https://ieeexplore.ieee.org/abstract/document/8413124/">Paper</a>]-->
        <br><br>
        </td>
    </tr>

    <tr>
        <td width="306">
        <img src="pics/software.jpg" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
        </td>
        <td><strong>Pulmonary Nodular Assisted Detection System Based on AI(V1.0)</strong><br>
            <em> Bin Li, <b>Yunhao Ge</b><br></em>
            <em>2018SR037095</em>.
<!--        <br>[<a href="https://ieeexplore.ieee.org/abstract/document/8413124/">Paper</a>]-->
        <br><br>
        </td>
    </tr>

    <tr>
        <td width="306">
        <img src="pics/patent1.jpg" width="285px" height= "170px" style="box-shadow: 4px 4px 8px #888">
        </td>
        <td><strong>A Two-Layer Barrier Free Parking Equipment Based on Bionic Manipulator</strong><br>
            <em><b>Yunhao Ge</b>, Shangze Yang, Zheng Zhang, Weixin Yan and Yanzheng Zhao <br></em>
            <em>CN201610712048</em>.
<!--        <br>[<a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w3/Xu_Dual-Mode_Vehicle_Motion_CVPR_2018_paper.pdf">Paper</a>]-->
        <br><br>
        </td>
    </tr>

    <tr>
        <td width="306">
        <img src="pics/patent2.png" width="285px" height= "180px" style="box-shadow: 4px 4px 8px #888">
        </td>
        <td><strong>A Double Decker Parking Equipment based on Shear Lifting Mechanism and Hydraulic Mechanism</strong><br>
            <em><b>Yunhao Ge</b>, Xulong Zhou, Peng Liu and Yanzheng Zhao <br></em>
            <em>CN201610704408</em>.
<!--        <br>[<a href="https://github.com/gyhandy/publication/blob/master/A%20Real-time%20Gesture%20Prediction%20System%20Using%20Neural%20Networks%20and%20Multimodal%20Fusion%20based%20on%20data%20glove.pdf">Paper</a>] -->
        <br><br>
        </td>
    </tr>
</table>
<br>
<!--
 <h3>Academice Service</h3>
<hr>
<table id="tbActivities" border="0" width="100%">
	Reviewer of the following conferences/journals:
    <p>IEEE Transactions on Multimedia (TMM) </p>
    <p>IEEE International Conference on Computer Vision (ICCV 2017)</p>
    <p>ACM Multimedia Conference (MM 2017)</p>
    <p>IEEE International Conference on Image Processing (ICIP 2017)</p>
    <p>AAAI Conference on Artificial Intelligence (AAAI 2016)</p>
</table> 
-->

<!-- <h2>OpenCourse Achievements</h2>-->
<!--      <h4> DeepLearning.ai</h4>-->
<!--      <ul>-->
<!--        <li>Neural Networks and Deep Learning</li>-->
<!--        <li>Improving Deep Neural Networks</li>-->
<!--        <li>Structuring Machine Learning Projects </li>-->
<!--		<li>Convolutional Neural Networks </li>-->
<!--  </ul> -->
<!--<br> -->
<!--
<h4>Links</h4>
<strong>
<a href="http://cs231n.stanford.edu/">CS231n@Stanford</a><br>
<a href="http://pytorch.org/">PyTorch</a><br>

</strong>
-->
<hr>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=F_s9W3nU5OYqMT1Q8FiSEnLSHBjVFBhCTQoaSexG7Mk'></script>
<p align="center"><font color="#999999">Last update: May. 3, 2021</font></p>



</body>

</html>
